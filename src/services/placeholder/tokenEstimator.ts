/**
 * Cost/Token Estimator (Placeholder)
 *
 * Future: Estimate token usage and cost per prompt per model
 * - Token counting (GPT tokenizer, Claude tokenizer)
 * - Cost calculation based on model pricing
 * - Context window warnings
 */

export function estimateTokens(_prompt: string, _model: string): number {
  throw new Error("Not implemented â€” token estimator is a future feature.");
}
